{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tsanyu20/bachelor_thesis/blob/main/Copy_of_Preview_Copy_of_Social_Media_Analysis_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6rVHL7U5qoD"
   },
   "source": [
    "# Social Media Analysis 101\n",
    "\n",
    "**Author**: [Yara Kyrychenko](https://www.sdmlab.psychol.cam.ac.uk/staff/yara-kyrychenko).\n",
    "\n",
    "\n",
    "\n",
    "**Contents**:\n",
    "1.   Scraping Telegram\n",
    "2.   Text Analysis\n",
    "3.   Statistics\n",
    "\n",
    "Add your secrets in the panel to the left under the key sign.\n",
    "  - You will need: `api_id`, `api_hash`, and `openai_key`.\n",
    "  \n",
    "Change runtime to GPU if you want to use GPU for open source zero shot classification.\n",
    "\n",
    "**Don't forget to validate your LLM labels for real studies!!!**\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/Tsanyu20/bachelor_thesis.git"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uEUS9_jxIqdL",
    "outputId": "e5e71d8b-7e95-4632-95ca-0612b0d1ccbb"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7TegdcizaN4Z"
   },
   "source": [
    "!pip install -r /content/bachelor_thesis/requirements.txt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Mpahbw2MiqZe"
   },
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "years = [2022, 2023, 2024, 2025]\n",
    "months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "dates = {}\n",
    "\n",
    "# for year in years:\n",
    "#   for month in months:\n",
    "#     dates[f\"{year}-{month}\"] = []\n",
    "with open('/content/bachelor_thesis/deoccupied/VKhersone.json', encoding='utf-8') as f:\n",
    "  data = json.load(f)\n",
    "\n",
    "for dic in data:\n",
    "  for year in years:\n",
    "    for month in months:\n",
    "      if re.findall(f\"{year}-{month}\", dic['date']):\n",
    "        content = []\n",
    "        if dic['text']:\n",
    "          content.append(dic['text'])\n",
    "        if dic['caption']:\n",
    "          content.append(dic['caption'])\n",
    "        if content:\n",
    "          if dates.get(f\"{year}-{month}\"):\n",
    "            dates[f\"{year}-{month}\"].append(content)\n",
    "          else :\n",
    "            dates[f\"{year}-{month}\"] = [content]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "dates"
   ],
   "metadata": {
    "id": "NuR3vPh2kQHd"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def extract_date(json_files):\n",
    "  years = [2022, 2023, 2024, 2025]\n",
    "  months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "  dates = {}\n",
    "\n",
    "  for file in json_files:\n",
    "    try:\n",
    "      with open(file,  encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "      for dic in data:\n",
    "        for year in years:\n",
    "          for month in months:\n",
    "            if re.findall(f\"{year}-{month}\", dic['date']):\n",
    "              content = []\n",
    "              if dic['text']:\n",
    "                content.append(dic['text'])\n",
    "              if dic['caption']:\n",
    "                content.append(dic['caption'])\n",
    "              if content:\n",
    "                if dates.get(f\"{year}-{month}\"):\n",
    "                  dates[f\"{year}-{month}\"].append(content)\n",
    "                else :\n",
    "                  dates[f\"{year}-{month}\"] = [content]\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "      print(f\"Error decoding JSON in file {file}: {e}\")\n",
    "\n",
    "  return dates"
   ],
   "metadata": {
    "id": "qVdHjCWaGGqq"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import glob\n",
    "occupied_sample = glob.glob(\"/content/bachelor_thesis/occupied/*.json\")\n",
    "oc_date = extract_date(occupied_sample)\n",
    "deoccupied_sample = glob.glob(\"/content/bachelor_thesis/deoccupied/*.json\")\n",
    "de_date = extract_date(deoccupied_sample)"
   ],
   "metadata": {
    "id": "r_9DwBmmcc7x"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print('Occupied:')\n",
    "for key, value in oc_date.items():\n",
    "  print(f\"{key}: {len(value)}\")\n",
    "print('------------------------------')\n",
    "print('Deoccupied:')\n",
    "for key, value in de_date.items():\n",
    "  print(f\"{key}: {len(value)}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78rHf_Iwdbzo",
    "outputId": "1d271d55-746f-485b-e61d-6c5b6d33f371"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract content from json files and identify language used"
   ],
   "metadata": {
    "id": "olLkHbe6yk4B"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9CEzXMw-g26x"
   },
   "source": [
    "import glob\n",
    "import json\n",
    "\n",
    "# Use this function to get all non-empty text/caption\n",
    "def extract_text(json_files):\n",
    "  all_content=[]\n",
    "  for file in json_files:\n",
    "        try:\n",
    "            with open(file, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                for dic in data:\n",
    "                  if dic['text']:\n",
    "                    all_content.append(dic['text'])\n",
    "                  if dic['caption']:\n",
    "                    all_content.append(dic['caption'])\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON in file {file}: {e}\")\n",
    "\n",
    "  if all_content:\n",
    "    return all_content\n",
    "  else:\n",
    "      print(\"No data found in JSON files.\")\n",
    "      return None\n",
    "\n",
    "# oc_json = glob.glob('/content/bachelor_thesis/occupied/*.json')\n",
    "# oc_content = extract_text(oc_json)\n",
    "de_json = glob.glob('/content/bachelor_thesis/deoccupied/*.json')\n",
    "de_content = extract_text(de_json)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BiCg42rhnXxH",
    "outputId": "847d4f3d-b698-4be1-f557-151c2cda23f3"
   },
   "source": [
    "from langdetect import detect\n",
    "\n",
    "count_ru = 0\n",
    "count_uk = 0\n",
    "\n",
    "de_uk = []\n",
    "for sentence in de_content:\n",
    "  try :\n",
    "    # Detect if it's uk or ru\n",
    "    lang = detect(sentence)\n",
    "    if (lang == 'ru'):\n",
    "      count_ru += 1\n",
    "    elif (lang == 'uk'):\n",
    "      count_uk += 1\n",
    "      de_uk.append(sentence)\n",
    "  except Exception as e:\n",
    "    # Remove the messages that can't be distinguished to one language\n",
    "    de_content.remove(sentence)\n",
    "\n",
    "print(f\"Count for Russian: {count_ru}, Count for Ukrainian {count_uk}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tfidf Vectorization\n"
   ],
   "metadata": {
    "id": "6AxDdmr3nWfb"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### In Ukrainian"
   ],
   "metadata": {
    "id": "7SgIFJ8CzBrC"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MPsMYITvacsT"
   },
   "source": [
    "!python -m spacy download uk_core_news_sm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hIvynhbpdXIF"
   },
   "source": [
    "# @title Perform lemmatization on dataset\n",
    "import spacy\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "import gensim\n",
    "\n",
    "#nlp_r = spacy.load('ru_core_news_sm')\n",
    "nlp_u = spacy.load('uk_core_news_sm')\n",
    "\n",
    "doc = []\n",
    "for sen in de_uk:\n",
    "  doc.append(nlp_u(sen))\n",
    "\n",
    "lemmatizer = nlp_u.get_pipe(\"lemmatizer\")\n",
    "processed_corpus_u =[[token.lemma_ for token in sen] for sen in doc]\n",
    "\n",
    "# Make the processed list as dictionary\n",
    "dictionary_u = corpora.Dictionary(processed_corpus_u)\n",
    "bow_corpus_u = [dictionary_u.doc2bow(text) for text in processed_corpus_u]\n",
    "\n",
    "\n",
    "# train the model\n",
    "tfidf = models.TfidfModel(bow_corpus_u)\n",
    "corpus_tfidf = tfidf[bow_corpus_u]\n",
    "\n",
    "# transform into numpy array\n",
    "\"\"\"corpus_csr = gensim.matutils.corpus2csc(corpus_tfidf)\n",
    "corpus_numpy = corpus_csr.T.toarray()\"\"\"\n",
    "tfidf_matrix_u = gensim.matutils.corpus2dense(corpus_tfidf, num_terms=len(dictionary_u)).T"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### In English"
   ],
   "metadata": {
    "id": "PCxYrn0M0vse"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# @title Translate into EN-US to perform vectorization\n",
    "import deepl\n",
    "\n",
    "auth_key = \"a7c78cad-9348-425d-be66-88410ea035ac:fx\"  # Replace with your key\n",
    "deepl_client = deepl.DeepLClient(auth_key)\n",
    "\n",
    "doc_e = []\n",
    "for sen in de_uk:\n",
    "  doc_e.append(deepl_client.translate_text(sen, target_lang=\"EN-US\").text)\n",
    "\n",
    "doc_e[0]"
   ],
   "metadata": {
    "id": "_yIP4WNYGgEN"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# @title Use TfidfVectorizer from sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=5, stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(doc_e)"
   ],
   "metadata": {
    "id": "aPOPPH4AjsLu"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use spacy and gensim to preprocess and tokenize"
   ],
   "metadata": {
    "id": "yfQi4jFnoHnG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!python -m spacy download en_core_web_sm"
   ],
   "metadata": {
    "id": "VVZR-s1-Lhqo",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "962906ad-f48c-48a9-f3d0-a9c1225322db"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "import gensim\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "documents=[]\n",
    "for sen in doc_e:\n",
    "  documents.append(nlp(sen))\n",
    "\n",
    "# Lemmatize\n",
    "lemmatizer = nlp.get_pipe(\"lemmatizer\")\n",
    "processed_corpus = [[token.lemma_ for token in sen] for sen in documents]\n",
    "\n",
    "# Define dictionary and count the frequency of each word\n",
    "dictionary = corpora.Dictionary(processed_corpus)\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
    "\n",
    "# train the model\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "\n",
    "# Transform into numpy array\n",
    "tfidf_matrix_g = gensim.matutils.corpus2dense(corpus_tfidf, num_terms=len(dictionary)).T"
   ],
   "metadata": {
    "id": "UNVjigAnLxs9"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare the plots"
   ],
   "metadata": {
    "id": "XUPWun2gvV-1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "pca_result = pca.fit_transform(tfidf_matrix) # with sklearn\n",
    "pca_result_g = pca.fit_transform(tfidf_matrix_g) # with gensim\n",
    "pca_result_u = pca.fit_transform(tfidf_matrix_u) # in ukranian"
   ],
   "metadata": {
    "id": "hNIcfnN_CHtJ"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Use sklearn TfidfVectorizer\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(pca_result[:, 0], pca_result[:, 1], c='blue', edgecolor='k', s=50)\n",
    "for i, txt in enumerate(doc_e):\n",
    "    plt.annotate(i, (pca_result[i, 0], pca_result[i, 1]))\n",
    "\n",
    "\n",
    "# Use spacy and gensim\n",
    "plt.scatter(pca_result_g[:, 0], pca_result_g[:, 1], c='orange', edgecolor='k', s=50)\n",
    "for i, txt in enumerate(doc_e):\n",
    "    plt.annotate(i, (pca_result_g[i, 0], pca_result_g[i, 1]))\n",
    "\n",
    "# Original Language\n",
    "plt.scatter(pca_result_u[:, 0], pca_result_u[:, 1], c='green', edgecolor='k', s=50)\n",
    "for i, txt in enumerate(doc_e):\n",
    "    plt.annotate(i, (pca_result_u[i, 0], pca_result_u[i, 1]))\n",
    "\n",
    "labels = ['sklearn', 'gensim', 'ukranian']\n",
    "plt.legend(labels)\n",
    "plt.title('PCA of TF-IDF Matrix')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "RxfWovcHlgHt",
    "outputId": "5d6b138e-d839-4316-bb47-858c2cac95da"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# KMeans clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(\n",
    "    n_clusters=4,\n",
    "    max_iter=100,\n",
    "    n_init=5,\n",
    ").fit(pca_result)\n",
    "\n",
    "labels = kmeans.predict(pca_result)\n",
    "# Make a scatter plot of xs and ys, using labels to define the colors\n",
    "plt.scatter(pca_result[:, 0], pca_result[:,1],alpha=0.5)\n",
    "# Assign the cluster centers: centroids\n",
    "centroids = kmeans.cluster_centers_\n",
    "# Assign the columns of centroids: centroids_x, centroids_y\n",
    "centroids_x = centroids[:,0]\n",
    "centroids_y = centroids[:,1]\n",
    "# Make a scatter plot of centroids_x and centroids_y\n",
    "plt.scatter(centroids_x,centroids_y,marker='D',s=50)\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "nSZIDHUn4bGr",
    "outputId": "e5d2e411-d536-4fce-9847-1de01e654d18"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Google Fact Check Tools API"
   ],
   "metadata": {
    "id": "uQ1PkGnY08G_"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "qHWP-tqq_cRB",
    "outputId": "a04af29b-816b-4506-dbf6-41feda103f59"
   },
   "source": [
    "import requests\n",
    "#https://developers.google.com/fact-check/tools/api/reference/rest/v1alpha1/claims/search\n",
    "from google.colab import userdata\n",
    "\n",
    "def fact_check_search(query, api_key):\n",
    "  # Base URL for the API\n",
    "  url = \"https://factchecktools.googleapis.com/v1alpha1/claims:search\"\n",
    "  # Parameters for the API request\n",
    "  params = {\n",
    "    'query': query, # Search term (string)\n",
    "    'languageCode': 'en', # Language (optional)\n",
    "    'key': api_key, # Your API key\n",
    "    'pageSize': 10 # Number of results returned,\n",
    "    # 'maxAgeDays': 30 # Maximum age of the results in days\n",
    "    }\n",
    "\n",
    "  # Make the GET request\n",
    "  response = requests.get(url, params=params)\n",
    "  # Handle response\n",
    "  if response.status_code == 200:\n",
    "    return response.json()\n",
    "  else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")\n",
    "    return None\n",
    "\n",
    "# Replace with your API key\n",
    "API_KEY = userdata.get('fact_check_apikey')\n",
    "search_query = \"Ukraine\"\n",
    "result = fact_check_search(search_query, API_KEY)\n",
    "\n",
    "# Print results\n",
    "if result:\n",
    "  for claim in result.get('claims', []):\n",
    "    print(f\"Claim: {claim.get('text')}\")\n",
    "    print(f\"Claimant: {claim.get('claimant')}\")\n",
    "    print(f\"Rating: {claim.get('claimReview', [{}])[0].get('textualRating')}\")\n",
    "    print(f\"URL: {claim.get('claimReview', [{}])[0].get('url')}\")\n",
    "    print(\"-\" * 40)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tWjvSLZ3xk5I"
   },
   "source": [
    "# @title Alternative: Use an open-source Library to get access to Fact Check Tools\n",
    "!pip install git+https://github.com/GONZOsint/factcheckexplorer.git"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jno0dEvw8AHp"
   },
   "source": [
    "import pandas as pd, numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhiWsG875ev-"
   },
   "source": [
    "## 1. Scraping Telegram"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YdVE4TLEiqY2",
    "outputId": "60ecd2f2-e81f-442b-d120-61261a3928cf"
   },
   "source": [
    "! pip install pyrogram\n",
    "! pip3 install -U tgcrypto"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jfddlDgDuUY4"
   },
   "source": [
    "Discover Telegram Channels: https://tgstat.ru/en\n",
    "\n",
    "Check out `pyrogram`: https://docs.pyrogram.org/\n",
    "\n",
    "Get the Telegram API id and hash: https://core.telegram.org/api/obtaining_api_id"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Gvdw-ALSipr4"
   },
   "source": [
    "from pyrogram import Client\n",
    "from google.colab import userdata\n",
    "\n",
    "api_id = int(userdata.get('api_id'))\n",
    "api_hash = userdata.get('api_hash')\n",
    "\n",
    "app = Client(\"UkraineRussiaCrisis\", api_id=api_id, api_hash=api_hash)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b71zgrIpiizi"
   },
   "source": [
    "# Use the existing event loop in Jupyter/IPython\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "import json\n",
    "from pyrogram.types import Message\n",
    "\n",
    "def get_reactions(message):\n",
    "    reactions = {}\n",
    "    if hasattr(message, \"reactions\") and message.reactions is not None:\n",
    "        for reaction in message.reactions.reactions:\n",
    "            reactions[reaction.emoji] = reaction.count\n",
    "    return reactions\n",
    "\n",
    "def get_urls(entities):\n",
    "    urls = []\n",
    "    if entities:\n",
    "        for entity in entities:\n",
    "            try:\n",
    "                if entity.url is not None:\n",
    "                    urls.append(entity.url)\n",
    "            except:\n",
    "                pass\n",
    "    return urls\n",
    "\n",
    "async def get_channel_history(chat_id, output_file=None, message_limit=15):\n",
    "    output_file = chat_id if output_file is None else output_file\n",
    "\n",
    "    if not app.is_connected:\n",
    "        await app.start()\n",
    "\n",
    "    chat = await app.get_chat(chat_id)\n",
    "    followers_count = chat.members_count or 0\n",
    "\n",
    "    all_messages, message_dicts = [], []\n",
    "    async for message in app.get_chat_history(chat_id, limit=message_limit):\n",
    "\n",
    "        all_messages.append(message)\n",
    "\n",
    "        message_dict = {\n",
    "            \"id\": message.id,\n",
    "            \"text\": message.text,\n",
    "            \"date\": message.date.isoformat(),\n",
    "            \"caption\": message.caption,\n",
    "            \"views\": message.views,\n",
    "            \"forwards\": message.forwards,\n",
    "            \"reactions\": get_reactions(message),\n",
    "            \"channel_memebers_count\": followers_count,\n",
    "            \"channel_username\": message.chat.username,\n",
    "            \"sender_username\": message.sender_chat.username,\n",
    "            \"channel_id\": message.chat.id,\n",
    "            \"sender_id\": message.sender_chat.id,\n",
    "            \"channel_is_verified\": message.chat.is_verified,\n",
    "            \"sender_is_verified\": message.sender_chat.is_verified,\n",
    "            \"reply_to_message_id\": message.reply_to_message_id,\n",
    "            \"reply_to_top_message_id\": message.reply_to_top_message_id,\n",
    "            \"video\": message.video.file_id if message.video else None,\n",
    "            \"photo\": message.photo.file_id if message.photo else None,\n",
    "            \"sticker\": message.sticker.file_id if message.sticker else None,\n",
    "            \"url\": get_urls(message.caption_entities)\n",
    "\n",
    "        }\n",
    "\n",
    "        message_dicts.append(message_dict)\n",
    "\n",
    "    with open(f'{output_file}.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(message_dicts, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    if app.is_connected:\n",
    "        await app.stop()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5pawSS1YUH9D"
   },
   "source": [
    "channels = pd.read_csv('/content/bachelor_thesis/UkraineTGChannels.csv')\n",
    "occupied = channels[channels['Category']=='Occupied'].Username.to_list()\n",
    "deoccupied = channels[channels['Category']=='De-occupied'].Username.to_list()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gpH9xzdgnsQb",
    "outputId": "7be1e440-2956-486a-ff75-3a28358718b2"
   },
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "occupied_sample = np.random.choice(occupied, min(25, len(occupied)), replace=False)\n",
    "deoccupied_sample = np.random.choice(deoccupied, min(25, len(deoccupied)),replace=False)\n",
    "\n",
    "print(f\"Sampled {len(occupied_sample)} occupied channels: {occupied_sample}\")\n",
    "print(f\"Sampled {len(deoccupied_sample)} deoccupied channels: {deoccupied_sample}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7udhZ6Pot_sA"
   },
   "source": [
    "nest_asyncio.apply()\n",
    "await get_channel_history(\"rian_ru\",message_limit=100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v0GI0AtazbFp",
    "outputId": "ec16baae-6efc-481d-a24c-f68d4e8bd3bf"
   },
   "source": [
    "nest_asyncio.apply()\n",
    "for chat_id in occupied_sample:\n",
    "    try:\n",
    "      await get_channel_history(chat_id,output_file=f'/content/bachelor_thesis/occupied/{chat_id}',message_limit=100)\n",
    "    except Exception as e:\n",
    "      print(f\"Error processing channel {chat_id}: {e}\")\n",
    "\n",
    "for chat_id in deoccupied_sample:\n",
    "    try:\n",
    "      await get_channel_history(chat_id,output_file=f'/content/bachelor_thesis/deoccupied/{chat_id}',message_limit=100)\n",
    "    except Exception as e:\n",
    "      print(f\"Error processing channel {chat_id}: {e}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DbOIPQWK6iIx",
    "ExecuteTime": {
     "end_time": "2025-05-02T11:31:46.857114Z",
     "start_time": "2025-05-02T11:31:43.268401Z"
    }
   },
   "source": [
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def json_to_df(json_files):\n",
    "    all_data = []\n",
    "    for file in json_files:\n",
    "        try:\n",
    "            with open(file, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                all_data.extend(data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON in file {file}: {e}\")\n",
    "\n",
    "    if all_data:\n",
    "      return pd.DataFrame(all_data)\n",
    "    else:\n",
    "      print(\"No data found in JSON files.\")\n",
    "      return None\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PQkPOaP3_Z1n",
    "ExecuteTime": {
     "end_time": "2025-05-02T13:16:56.402725Z",
     "start_time": "2025-05-02T13:16:56.113Z"
    }
   },
   "source": [
    "json_files = glob.glob(\"./occupied/*.json\")\n",
    "oc_df = json_to_df(json_files)\n",
    "json_files = glob.glob(\"./deoccupied/*.json\")\n",
    "deoc_df = json_to_df(json_files)"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eJCZl7oGq4tG",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e81fab31-cee1-4972-8dc6-f91cefcb0087",
    "ExecuteTime": {
     "end_time": "2025-05-02T13:16:58.556131Z",
     "start_time": "2025-05-02T13:16:58.521930Z"
    }
   },
   "source": [
    "oc_df['category'] = 'occupied'\n",
    "deoc_df['category'] = 'deoccupied'\n",
    "df = pd.concat([oc_df, deoc_df], ignore_index=True)"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T13:18:11.860915Z",
     "start_time": "2025-05-02T13:18:11.758677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "small_df = pd.read_csv('results_df_all_custom.csv')\n",
    "small_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Unnamed: 0.1  Unnamed: 0     id  \\\n",
       "0               0           0    302   \n",
       "1               1           1   7336   \n",
       "2               2           2  25763   \n",
       "3               3           3   7096   \n",
       "4               4           4   1967   \n",
       "..            ...         ...    ...   \n",
       "495           495         495  21901   \n",
       "496           496         496  21855   \n",
       "497           497         497   6538   \n",
       "498           498         498   1702   \n",
       "499           499         499   1185   \n",
       "\n",
       "                                                  text                 date  \\\n",
       "0                                                  NaN  2024-12-15T08:01:07   \n",
       "1    üíî –° 1 —è–Ω–≤–∞—Ä—è –≥–æ—Å–ø–æ—à–ª–∏–Ω–∞ –Ω–∞ —Ä–∞–∑–≤–æ–¥ –≤—ã—Ä–∞—Å—Ç–µ—Ç –≤ 8...  2024-12-31T07:58:39   \n",
       "2    ‚ù§Ô∏è –í–∑—è—Ç–∏–µ –ë–µ—Ä–¥–∏–Ω–∞ - –≤–±—Ä–æ—Å –≥—Ä–µ–±–Ω–µ–π –∏ –ø–∞–Ω–∏–∫–µ—Ä–æ–≤....  2025-01-05T09:17:31   \n",
       "3                                                  NaN  2025-01-01T11:30:23   \n",
       "4    –°–µ–º–µ–Ω—ñ–≤–∫–∞ - –ö–ê–ë–∏ –≤ –º—ñ—Å—Ç–æ... \\n\\n–î–µ—Ç–∞–ª—ñ –∑ –æ—Ñ—ñ—Ü—ñ...  2025-01-04T19:22:59   \n",
       "..                                                 ...                  ...   \n",
       "495                                                NaN  2025-01-08T18:28:18   \n",
       "496                                                NaN  2025-01-06T07:05:58   \n",
       "497                                                NaN  2024-12-29T07:55:42   \n",
       "498                       ‚ùóÔ∏è–°–æ–æ–±—â–∞—é—Ç –æ –≤–∑—Ä—ã–≤–µ –≤ –†–æ–≤–Ω–æ–º  2022-10-10T08:16:49   \n",
       "499                                                NaN  2025-01-07T07:40:41   \n",
       "\n",
       "                                               caption    views  forwards  \\\n",
       "0    üí°‚ùó–ì—Ä–∞—Ñ—ñ–∫–∏ –≤—ñ–¥–∫–ª—é—á–µ–Ω—å —Å–≤—ñ—Ç–ª–∞ –ø–æ –ß–µ—Ä–Ω—ñ–≥—ñ–≤—â–∏–Ω—ñ –Ω–∞...    832.0       1.0   \n",
       "1                                                  NaN    226.0       1.0   \n",
       "2                                                  NaN    850.0       1.0   \n",
       "3    –§–µ—Ä–º–µ—Ä–∏ –•–µ—Ä—Å–æ–Ω—â–∏–Ω–∏ –ø–ª–∞–Ω—É—é—Ç—å —Ä–æ–∑—à–∏—Ä–∏—Ç–∏ –ø–ª–æ—â—ñ –ø—ñ...    423.0       0.0   \n",
       "4                                                  NaN   6334.0      23.0   \n",
       "..                                                 ...      ...       ...   \n",
       "495  –ù–æ–≤–æ–≥–æ–¥–Ω–∏–µ –ø—Ä–∞–∑–¥–Ω–∏–∫–∏ –ø–æ–¥–æ—à–ª–∏ –∫ –∫–æ–Ω—Ü—É ‚Äî –∞—Ç–º–æ—Å—Ñ–µ...  60207.0     232.0   \n",
       "496  ‚ö°Ô∏è–û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ –ö—É—Ä–∞—Ö–æ–≤–∞ –ª–∏—à–∏–ª–æ –í–°–£ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏...  59669.0     214.0   \n",
       "497  –î–æ—Ä–æ–≥–∏–µ –∑–µ–º–ª—è–∫–∏, –ø–æ–∑–¥—Ä–∞–≤–ª–µ–Ω–∏—è —Å –Ω–∞—Å—Ç—É–ø–∞—é—â–∏–º –ù–æ...  36084.0      97.0   \n",
       "498                                                NaN   1442.0       2.0   \n",
       "499  –°–í–ï–¢–õ–û–ì–û –†–û–ñ–î–ï–°–¢–í–ê üéÑ\\n–ú–∏—Ä–∞, –ª—é–±–≤–∏ –∏ –∑–¥–æ—Ä–æ–≤—å—è –≤...    927.0       1.0   \n",
       "\n",
       "                                             reactions  \\\n",
       "0                                                   {}   \n",
       "1                                             {'ü§¨': 1}   \n",
       "2                                    {'üôè': 15, 'ü•¥': 1}   \n",
       "3                                             {'üëç': 3}   \n",
       "4          {'üò±': 36, 'üò≠': 31, 'ü§¨': 26, 'üíØ': 3, 'ü§£': 1}   \n",
       "..                                                 ...   \n",
       "495  {'üôè': 86, 'üëè': 71, '‚ù§': 67, 'üî•': 62, 'üëç': 38, ...   \n",
       "496  {'üôè': 107, '\\U0001fae1': 80, 'üî•': 67, 'üëè': 63,...   \n",
       "497  {'üëç': 232, '‚ù§': 89, 'ü•∞': 14, 'üò¢': 13, 'üëè': 8, ...   \n",
       "498                                           {'üò¢': 1}   \n",
       "499                                                 {}   \n",
       "\n",
       "     channel_memebers_count  ... polarization impersonation  conspiracy  \\\n",
       "0                       444  ...            0             0           0   \n",
       "1                      1729  ...            0             0           0   \n",
       "2                      2799  ...            3             0           1   \n",
       "3                      4752  ...            0             0           0   \n",
       "4                      6118  ...            3             0           0   \n",
       "..                      ...  ...          ...           ...         ...   \n",
       "495                  308903  ...            0             0           0   \n",
       "496                  308903  ...            3             0           1   \n",
       "497                   15812  ...            0             0           0   \n",
       "498                     737  ...            0             0           0   \n",
       "499                     562  ...            0             0           0   \n",
       "\n",
       "     trolling  pro-ukrainian  pro-russian  pro-ukrainian-mDeBERTa  \\\n",
       "0           0              0            0                0.511689   \n",
       "1           0              0            0                0.455062   \n",
       "2           2              0            4                0.638906   \n",
       "3           0              0            0                0.477264   \n",
       "4           2              4            0                0.643907   \n",
       "..        ...            ...          ...                     ...   \n",
       "495         0              0            0                0.588331   \n",
       "496         2              0            5                0.477560   \n",
       "497         0              0            3                0.423041   \n",
       "498         0              0            0                0.553514   \n",
       "499         0              0            0                0.393736   \n",
       "\n",
       "     pro-russian-mDeBERTa pro-ukrainian-custom pro-russian-custom  \n",
       "0                0.488311             0.995916           0.004084  \n",
       "1                0.544938             0.007027           0.992972  \n",
       "2                0.361094             0.006853           0.993147  \n",
       "3                0.522736             0.995770           0.004230  \n",
       "4                0.356093             0.995826           0.004174  \n",
       "..                    ...                  ...                ...  \n",
       "495              0.411669             0.007292           0.992708  \n",
       "496              0.522440             0.006721           0.993279  \n",
       "497              0.576959             0.006717           0.993283  \n",
       "498              0.446486             0.223716           0.776284  \n",
       "499              0.606264             0.011299           0.988701  \n",
       "\n",
       "[500 rows x 37 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>caption</th>\n",
       "      <th>views</th>\n",
       "      <th>forwards</th>\n",
       "      <th>reactions</th>\n",
       "      <th>channel_memebers_count</th>\n",
       "      <th>...</th>\n",
       "      <th>polarization</th>\n",
       "      <th>impersonation</th>\n",
       "      <th>conspiracy</th>\n",
       "      <th>trolling</th>\n",
       "      <th>pro-ukrainian</th>\n",
       "      <th>pro-russian</th>\n",
       "      <th>pro-ukrainian-mDeBERTa</th>\n",
       "      <th>pro-russian-mDeBERTa</th>\n",
       "      <th>pro-ukrainian-custom</th>\n",
       "      <th>pro-russian-custom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-15T08:01:07</td>\n",
       "      <td>üí°‚ùó–ì—Ä–∞—Ñ—ñ–∫–∏ –≤—ñ–¥–∫–ª—é—á–µ–Ω—å —Å–≤—ñ—Ç–ª–∞ –ø–æ –ß–µ—Ä–Ω—ñ–≥—ñ–≤—â–∏–Ω—ñ –Ω–∞...</td>\n",
       "      <td>832.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>444</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.511689</td>\n",
       "      <td>0.488311</td>\n",
       "      <td>0.995916</td>\n",
       "      <td>0.004084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7336</td>\n",
       "      <td>üíî –° 1 —è–Ω–≤–∞—Ä—è –≥–æ—Å–ø–æ—à–ª–∏–Ω–∞ –Ω–∞ —Ä–∞–∑–≤–æ–¥ –≤—ã—Ä–∞—Å—Ç–µ—Ç –≤ 8...</td>\n",
       "      <td>2024-12-31T07:58:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>226.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'ü§¨': 1}</td>\n",
       "      <td>1729</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.455062</td>\n",
       "      <td>0.544938</td>\n",
       "      <td>0.007027</td>\n",
       "      <td>0.992972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25763</td>\n",
       "      <td>‚ù§Ô∏è –í–∑—è—Ç–∏–µ –ë–µ—Ä–¥–∏–Ω–∞ - –≤–±—Ä–æ—Å –≥—Ä–µ–±–Ω–µ–π –∏ –ø–∞–Ω–∏–∫–µ—Ä–æ–≤....</td>\n",
       "      <td>2025-01-05T09:17:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>850.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'üôè': 15, 'ü•¥': 1}</td>\n",
       "      <td>2799</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.638906</td>\n",
       "      <td>0.361094</td>\n",
       "      <td>0.006853</td>\n",
       "      <td>0.993147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-01T11:30:23</td>\n",
       "      <td>–§–µ—Ä–º–µ—Ä–∏ –•–µ—Ä—Å–æ–Ω—â–∏–Ω–∏ –ø–ª–∞–Ω—É—é—Ç—å —Ä–æ–∑—à–∏—Ä–∏—Ç–∏ –ø–ª–æ—â—ñ –ø—ñ...</td>\n",
       "      <td>423.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'üëç': 3}</td>\n",
       "      <td>4752</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.477264</td>\n",
       "      <td>0.522736</td>\n",
       "      <td>0.995770</td>\n",
       "      <td>0.004230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1967</td>\n",
       "      <td>–°–µ–º–µ–Ω—ñ–≤–∫–∞ - –ö–ê–ë–∏ –≤ –º—ñ—Å—Ç–æ... \\n\\n–î–µ—Ç–∞–ª—ñ –∑ –æ—Ñ—ñ—Ü—ñ...</td>\n",
       "      <td>2025-01-04T19:22:59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6334.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>{'üò±': 36, 'üò≠': 31, 'ü§¨': 26, 'üíØ': 3, 'ü§£': 1}</td>\n",
       "      <td>6118</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.643907</td>\n",
       "      <td>0.356093</td>\n",
       "      <td>0.995826</td>\n",
       "      <td>0.004174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>495</td>\n",
       "      <td>21901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-08T18:28:18</td>\n",
       "      <td>–ù–æ–≤–æ–≥–æ–¥–Ω–∏–µ –ø—Ä–∞–∑–¥–Ω–∏–∫–∏ –ø–æ–¥–æ—à–ª–∏ –∫ –∫–æ–Ω—Ü—É ‚Äî –∞—Ç–º–æ—Å—Ñ–µ...</td>\n",
       "      <td>60207.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>{'üôè': 86, 'üëè': 71, '‚ù§': 67, 'üî•': 62, 'üëç': 38, ...</td>\n",
       "      <td>308903</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.588331</td>\n",
       "      <td>0.411669</td>\n",
       "      <td>0.007292</td>\n",
       "      <td>0.992708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>21855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-06T07:05:58</td>\n",
       "      <td>‚ö°Ô∏è–û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ –ö—É—Ä–∞—Ö–æ–≤–∞ –ª–∏—à–∏–ª–æ –í–°–£ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏...</td>\n",
       "      <td>59669.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>{'üôè': 107, '\\U0001fae1': 80, 'üî•': 67, 'üëè': 63,...</td>\n",
       "      <td>308903</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.477560</td>\n",
       "      <td>0.522440</td>\n",
       "      <td>0.006721</td>\n",
       "      <td>0.993279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>497</td>\n",
       "      <td>6538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-29T07:55:42</td>\n",
       "      <td>–î–æ—Ä–æ–≥–∏–µ –∑–µ–º–ª—è–∫–∏, –ø–æ–∑–¥—Ä–∞–≤–ª–µ–Ω–∏—è —Å –Ω–∞—Å—Ç—É–ø–∞—é—â–∏–º –ù–æ...</td>\n",
       "      <td>36084.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>{'üëç': 232, '‚ù§': 89, 'ü•∞': 14, 'üò¢': 13, 'üëè': 8, ...</td>\n",
       "      <td>15812</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.423041</td>\n",
       "      <td>0.576959</td>\n",
       "      <td>0.006717</td>\n",
       "      <td>0.993283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>1702</td>\n",
       "      <td>‚ùóÔ∏è–°–æ–æ–±—â–∞—é—Ç –æ –≤–∑—Ä—ã–≤–µ –≤ –†–æ–≤–Ω–æ–º</td>\n",
       "      <td>2022-10-10T08:16:49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1442.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'üò¢': 1}</td>\n",
       "      <td>737</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.553514</td>\n",
       "      <td>0.446486</td>\n",
       "      <td>0.223716</td>\n",
       "      <td>0.776284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>499</td>\n",
       "      <td>1185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-07T07:40:41</td>\n",
       "      <td>–°–í–ï–¢–õ–û–ì–û –†–û–ñ–î–ï–°–¢–í–ê üéÑ\\n–ú–∏—Ä–∞, –ª—é–±–≤–∏ –∏ –∑–¥–æ—Ä–æ–≤—å—è –≤...</td>\n",
       "      <td>927.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>562</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.393736</td>\n",
       "      <td>0.606264</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>0.988701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 37 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNsYLT_a5b9S"
   },
   "source": [
    "## 2. Text Analysis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NylQ3YGwDTb-",
    "outputId": "9988e9fa-3cb8-4b39-f968-28458ac931bc"
   },
   "source": [
    "df[['text', 'caption']] = df[['text', 'caption']].fillna(\"\")\n",
    "df['all_text'] = df['caption'] + ' ' + df['text']\n",
    "df = df[df['all_text'] != ' ']\n",
    "df['all_text_prep'] = df['all_text'].apply(lambda x: x[:512] + '...' if len(x) > 512 else x)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WxXYlrLosoG1",
    "outputId": "97bf41b7-fdf5-4c08-aa30-1b7a4b9e59ab"
   },
   "source": [
    "n_samples = 250\n",
    "dfsmall = df.groupby('category').apply(lambda x: x.sample(n=n_samples, random_state=42)).reset_index(drop=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-q6HWoUbRNw"
   },
   "source": [
    "### 2.1 ChatGPT\n",
    "\n",
    "Get openai api key: https://platform.openai.com/docs/overview"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5QtA2sX25_Sj"
   },
   "source": [
    "%%capture\n",
    "!pip install openai==1.55.3 httpx==0.27.2 --force-reinstall --quiet"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Kq1YQZO8_fdJ"
   },
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "openai.api_key = userdata.get('openai_key')\n",
    "client = OpenAI(api_key=userdata.get('openai_key'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SvuNm-ezv9hG"
   },
   "source": [
    "def analyze_texts(texts):\n",
    "    results = []\n",
    "    for text in texts:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You are an assistant that analyzes Telegram posts for specific linguistic categories. \"\n",
    "                        \"For each input text, return a JSON object with the following keys: \"\n",
    "                        \"'discrediting', 'emotion', 'polarization', 'impersonation', 'conspiracy', 'trolling', \"\n",
    "                        \"'pro-ukrainian', 'pro-russian'.\"\n",
    "                        \"Each key should have a value between 0 and 6 indicating the intensity of the category.\"\n",
    "                        \"Discrediting refers to discrediting opponents or creating doubt about them.\"\n",
    "                        \"Emotion refers to the use of outrage or highly emotive language to manipulate people.\"\n",
    "                        \"Polarization here means using divisive issues to drive a wedge between two groups.\"\n",
    "                        \"Impersonation refers to misusing the identity of politicians, experts, or celebrities.\"\n",
    "                        \"Conspiracy refers to casting doubt on mainstream narratives by providing an attractive story in which a small sinister group of people is responsible for doing harm to many.\"\n",
    "                        \"Trolling is aimed at eliciting reactions from people by provoking them.\"\n",
    "                        \"Finally, rate if the post has a pro-Ukrainian or a pro-Russian view on the war in Ukraine.\"\n",
    "                    ),\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": f\"Analyze this post: {text}\"},\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "            response_format = { \"type\": \"json_object\" },\n",
    "        )\n",
    "        results.append(response.choices[0].message.content)\n",
    "    return results"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vESjNA4WEkYG"
   },
   "source": [
    "# 500 posts took around 16 minutes\n",
    "results = analyze_texts(dfsmall.all_text_prep)\n",
    "results_df = pd.DataFrame([json.loads(result) for result in results])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "Rj-Cdt4zxN6t",
    "outputId": "a7906490-68ce-448d-8194-f8cf32f27aef"
   },
   "source": [
    "results_df_all = pd.concat([dfsmall, results_df], axis=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wWaLr6SbEsZE",
    "outputId": "19b758cd-dea4-44d0-8ab0-a887f0b1f4ae"
   },
   "source": [
    "for i, row in results_df_all[:10].iterrows():\n",
    "    print(f\"Category: {row['category']}\")\n",
    "    print(f\"Post: {row['all_text']}\")\n",
    "    print(f\"Discrediting: {row['discrediting']}\")\n",
    "    print(f\"Emotion: {row['emotion']}\")\n",
    "    print(f\"Polarization: {row['polarization']}\")\n",
    "    print(f\"Impersonation: {row['impersonation']}\")\n",
    "    print(f\"Conspiracy: {row['conspiracy']}\")\n",
    "    print(f\"Trolling: {row['trolling']}\")\n",
    "    print(f\"Pro-Ukrainian: {row['pro-ukrainian']}\")\n",
    "    print(f\"Pro-Russian: {row['pro-russian']}\")\n",
    "    print()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZD4NEY-HbL8Y"
   },
   "source": [
    "### 2.2 Open source models"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iscLO1TPdqp-"
   },
   "source": [
    "results_df_all = pd.read_csv('results_df_all_custom.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S20-FqOQbJFB",
    "outputId": "2d344539-ef95-454b-eaff-e912abb5c3c4"
   },
   "source": [
    "! pip install 'transformers[torch]'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "RFhvzwEwbHRG",
    "outputId": "f3a21b27-4c45-49ae-cd7d-8111beff088d"
   },
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\",\n",
    "                      device=0 if torch.cuda.is_available() else -1)\n",
    "sequence_to_classify = \"–†—É—Å–Ω—è - –Ω–µ –ª—é–¥–∏.\"\n",
    "candidate_labels = [\"pro-russian\",'pro-ukrainian']\n",
    "output = classifier(sequence_to_classify, candidate_labels, multi_label=False)\n",
    "print(output)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNZU-2PWdIHM",
    "outputId": "44848bfd-e8ea-441c-ffdf-3ad66c2e6ea3"
   },
   "source": [
    "sequence_to_classify = \"–†—É—Å–Ω—è - –Ω–µ –ª—é–¥–∏.\"\n",
    "candidate_labels = [\"solidarity with Ukraine or Ukrainians\",'other']\n",
    "output = classifier(sequence_to_classify, candidate_labels, multi_label=False)\n",
    "print(output)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIDEj9o9dRwv",
    "outputId": "1f5d7c1b-941d-4bac-e7b9-41870b33cd42"
   },
   "source": [
    "sequence_to_classify = \"–†—É—Å–Ω—è - –Ω–µ –ª—é–¥–∏.\"\n",
    "candidate_labels = [\"hostility towards Russia or Russians\",'other']\n",
    "output = classifier(sequence_to_classify, candidate_labels, multi_label=False)\n",
    "print(output)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nn5QJuy-fHGS",
    "outputId": "42669fd0-48e9-4af9-bd37-782d1973a81f"
   },
   "source": [
    "candidate_labels = [\"pro-russian\",'pro-ukrainian']\n",
    "output = classifier(list(results_df_all['all_text_prep'].values), candidate_labels, multi_label=False)\n",
    "print(output)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "T1G6HMW-fukr"
   },
   "source": [
    "results2 = pd.DataFrame([\n",
    "    {\n",
    "        **{label: score for label, score in zip(item['labels'], item['scores'])}\n",
    "    }\n",
    "    for item in output\n",
    "])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "tdrFrjq0n_25",
    "outputId": "bc288a74-9297-4ee4-c715-8a149b8099db"
   },
   "source": [
    "results2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Wz8yWNnSXFiX"
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TA0F6nGTjELS"
   },
   "source": [
    "results2.columns = ['pro-ukrainian-mDeBERTa','pro-russian-mDeBERTa']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgR0_eVTuC-x"
   },
   "source": [
    "### 2.3 Custom models\n",
    "\n",
    "Fine-tuning a language model: https://huggingface.co/docs/transformers/en/training\n",
    "\n",
    "Ukraine POV model: https://huggingface.co/YaraKyrychenko/ukraine-war-pov"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "BY-qicpHuBFe",
    "outputId": "481adfb2-74e6-41ab-c775-acfad47551fb"
   },
   "source": [
    "custom_classifier = pipeline(\"text-classification\",\n",
    "                             model='YaraKyrychenko/ukraine-war-pov',\n",
    "                             device=0 if torch.cuda.is_available() else -1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pLeiZBr6ueMK",
    "outputId": "806f82dd-c10b-4c2d-8739-e97e3e78c92b"
   },
   "source": [
    "custom_output = custom_classifier(list(results_df_all['all_text_prep'].values),return_all_scores=True)\n",
    "print(custom_output)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cUF4L4qgu880"
   },
   "source": [
    "results_custom = pd.DataFrame([\n",
    "    {item['label']: item['score'] for item in row}\n",
    "    for row in custom_output\n",
    "])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "vUCw8iTj6DLi",
    "outputId": "a2b1531f-1ff4-4fdb-ed61-84a948560947"
   },
   "source": [
    "results_custom"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CdEGicSOwGxW"
   },
   "source": [
    "results_custom.columns = ['pro-ukrainian-custom','pro-russian-custom']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8H6mujlsusoV"
   },
   "source": [
    "results_df_all = pd.concat([results_df_all, results2,results_custom], axis=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCsIOJnSDJrt"
   },
   "source": [
    "### 2.4 Comparison"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QdXpBoVeitd1"
   },
   "source": [
    "results_df_all['ur'] = results_df_all['pro-ukrainian'] - results_df_all['pro-russian']\n",
    "results_df_all['ua_bin'] = results_df_all['ur'].apply(lambda x: 1 if x > 3 else 0)\n",
    "results_df_all['ru_bin'] = results_df_all['ur'].apply(lambda x: 1 if x < -3 else 0)\n",
    "pd.crosstab(results_df_all['ua_bin'], results_df_all['ru_bin'])\n",
    "\n",
    "results_df_all['ur_mDeBERTa'] = results_df_all['pro-ukrainian-mDeBERTa'] - results_df_all['pro-russian-mDeBERTa']\n",
    "results_df_all['ua_mDeBERTa'] = results_df_all['ur_mDeBERTa'].apply(lambda x: 1 if x > 0.15 else 0)\n",
    "results_df_all['ru_mDeBERTa'] = results_df_all['ur_mDeBERTa'].apply(lambda x: 1 if x < -0.15 else 0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fTpD1jKSwXLh"
   },
   "source": [
    "\n",
    "results_df_all['ur_custom'] = results_df_all['pro-ukrainian-custom'] - results_df_all['pro-russian-custom']\n",
    "results_df_all['ua_custom'] = results_df_all['ur_custom'].apply(lambda x: 1 if x > 0.95 else 0)\n",
    "results_df_all['ru_custom'] = results_df_all['ur_custom'].apply(lambda x: 1 if x < -0.95 else 0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "2-57JG4rkQyk",
    "outputId": "1d789cae-c1c6-4ffb-eec1-b1a9d7623e3f"
   },
   "source": [
    "pd.crosstab(results_df_all['ua_mDeBERTa'], results_df_all['ru_mDeBERTa'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "7JvQNWXzwiFo",
    "outputId": "d94b3c22-9a86-4410-a6c6-9f26eba11828"
   },
   "source": [
    "pd.crosstab(results_df_all['ua_custom'], results_df_all['ru_custom'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zD77R4FlmaOD",
    "outputId": "9d1572cf-be29-4e7a-f4ee-a7ea625596ef"
   },
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "columns = ['ua_mDeBERTa','ru_mDeBERTa']\n",
    "corr_dict = {\n",
    "    'ua_mDeBERTa':'ua_bin',\n",
    "    'ru_mDeBERTa':'ru_bin'\n",
    "}\n",
    "\n",
    "for column in columns:\n",
    "    conf_matrix = confusion_matrix(results_df_all[corr_dict[column]], results_df_all[column])\n",
    "    accuracy = accuracy_score(results_df_all[corr_dict[column]], results_df_all[column])\n",
    "    f1 = f1_score(results_df_all[corr_dict[column]], results_df_all[column], average='macro')\n",
    "\n",
    "    print(f'Column: {column}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['NO', 'YES'], yticklabels=['NO', 'YES'])\n",
    "    plt.xlabel('DeBERTa')\n",
    "    plt.ylabel('ChatGPT')\n",
    "    plt.title(f'Confusion Matrix for {column}')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JN0r3FBzw9pN",
    "outputId": "73130ad9-af33-417e-aeab-f78208c3669a"
   },
   "source": [
    "columns = ['ua_custom','ru_custom']\n",
    "corr_dict = {\n",
    "    'ua_custom':'ua_bin',\n",
    "    'ru_custom':'ru_bin'\n",
    "}\n",
    "\n",
    "for column in columns:\n",
    "    conf_matrix = confusion_matrix(results_df_all[corr_dict[column]], results_df_all[column])\n",
    "    accuracy = accuracy_score(results_df_all[corr_dict[column]], results_df_all[column])\n",
    "    f1 = f1_score(results_df_all[corr_dict[column]], results_df_all[column], average='macro')\n",
    "\n",
    "    print(f'Column: {column}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['NO', 'YES'], yticklabels=['NO', 'YES'])\n",
    "    plt.xlabel('Custom')\n",
    "    plt.ylabel('ChatGPT')\n",
    "    plt.title(f'Confusion Matrix for {column}')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_EVHRZ_3Z2s"
   },
   "source": [
    "## 3. Statistics\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0dNj-5HC3kZ"
   },
   "source": [
    "Hypotheses testing, e.g.:\n",
    "- H1: Emotional content has an effect on forwards.\n",
    "- H0: Emotional content has no effect on forwards.\n",
    "\n",
    "Or:\n",
    "- H1: Pro-Ukrainian/Pro-Russian content will get more forwards in deoccupied/occupied channels. (IE The interaction between content type and channel type has an effect on forwards.)\n",
    "\n",
    "We want to control for how many people viewed the message, for instance, and other linguistic categories."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "tI6dfb9u9AV3",
    "outputId": "ddb982c4-1f0c-484b-81eb-5b295c924630"
   },
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(results_df_all['forwards'], kde=True, bins=10, color='skyblue')\n",
    "plt.title('Distribution of Forwards')\n",
    "plt.xlabel('Forwards')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B8YF7Vcu-uxl",
    "outputId": "1ca91c76-4687-4991-a313-286c161ec632"
   },
   "source": [
    "print(f\"Mean of forwards: {results_df_all['forwards'].mean()}\")\n",
    "print(f\"Standard deviation of forwards: {results_df_all['forwards'].std()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "b4Yb_3xx9EDP",
    "outputId": "0213240c-c497-426b-9052-a3fde7fe5cc7"
   },
   "source": [
    "results_df_all['log_forwards'] = np.log(1 + results_df_all['forwards'])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(results_df_all['log_forwards'], kde=True, bins=10, color='skyblue')\n",
    "plt.title('Distribution of Log Forwards')\n",
    "plt.xlabel('Log Forwards')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHWyaBF3_CvC"
   },
   "source": [
    "We could try using [negative binomial regression](https://en.wikipedia.org/wiki/Poisson_regression), which is good for overdispersed count data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IWdviFel066V"
   },
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "results_df_all['views_scaled'] = scaler.fit_transform(results_df_all[['views']])\n",
    "\n",
    "results_df_all['occupied'] = results_df_all['category'].apply(lambda x: 1 if x == 'occupied' else 0)\n",
    "results_df_all[\"pro-ru in occupied\"] = results_df_all['pro-russian']*results_df_all['occupied']\n",
    "results_df_all[\"pro-ua in occupied\"] = results_df_all['pro-ukrainian']*results_df_all['occupied']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mEPF0QEzxYG9"
   },
   "source": [
    "# dependent variable\n",
    "dv = 'forwards'\n",
    "\n",
    "# independent variables\n",
    "predictors = ['pro-ukrainian', 'pro-russian',\n",
    "              'views_scaled', # control variable\n",
    "              'discrediting', 'emotion', 'polarization',\n",
    "              'impersonation', 'conspiracy', 'trolling']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8uAsOeHo3Y6L",
    "outputId": "c6ab1549-9f3f-4d6f-c9c2-9549a4374ad3"
   },
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = results_df_all[['occupied','pro-ru in occupied',\"pro-ua in occupied\"]+predictors]\n",
    "X = sm.add_constant(X)           # Add constant for the intercept\n",
    "y = results_df_all[dv]\n",
    "\n",
    "model = sm.GLM(y, X, family=sm.families.NegativeBinomial()).fit()\n",
    "\n",
    "print(model.summary())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "MJBcm5Qm3S6y",
    "outputId": "5e0644b3-df1d-4558-edcb-ff8a150e0db6"
   },
   "source": [
    "def dw_plot(model):\n",
    "    err_series = model.params - model.conf_int()[0]\n",
    "    coef_df = pd.DataFrame({'coef': np.exp(model.params.values[1:]),\n",
    "                        'err': err_series.values[1:],\n",
    "                        'varname': err_series.index.values[1:]\n",
    "                       })\n",
    "    coef_df = coef_df[coef_df['varname'] != 'views_scaled']\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "\n",
    "    coef_df.plot(x='varname', y='coef', kind='barh',\n",
    "             ax=ax, color='none',\n",
    "             xerr='err', legend=False, linewidth=1.5)\n",
    "\n",
    "\n",
    "    ax.scatter(coef_df['coef'], np.arange(coef_df.shape[0]),\n",
    "           marker='s', s=120, color='black')\n",
    "\n",
    "\n",
    "    ax.axvline(x=1, linestyle='--', color='black', linewidth=2)\n",
    "\n",
    "\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ax.grid(True, axis='x', linestyle='--', alpha=0.6)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "dw_plot(model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjk11pcDA8ez"
   },
   "source": [
    "For a unit increase in trolling, the expected forwards rate increases by around exp(0.6013) - 1 = 82.45%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "765XHaITyvP5"
   },
   "source": [
    "Occupied"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OOfVUHMUylDN",
    "outputId": "6b93b93a-9f64-44a2-cc38-7057da48ae33"
   },
   "source": [
    "X = results_df_all[results_df_all['occupied']==1][predictors]\n",
    "X = sm.add_constant(X)\n",
    "y = results_df_all[results_df_all['occupied']==1][dv]\n",
    "\n",
    "model = sm.GLM(y, X, family=sm.families.NegativeBinomial()).fit()\n",
    "\n",
    "print(model.summary())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "JSxj5APT8NjS",
    "outputId": "e3a7afaf-f1f3-4132-91df-c7f728e337ae"
   },
   "source": [
    "dw_plot(model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HG9Brg4xy7P5",
    "outputId": "c1530a3d-e861-401b-ef03-d4eda9094137"
   },
   "source": [
    "X = results_df_all[results_df_all['occupied']==0][predictors]\n",
    "X = sm.add_constant(X)\n",
    "y = results_df_all[results_df_all['occupied']==0][dv]\n",
    "\n",
    "model = sm.GLM(y, X, family=sm.families.NegativeBinomial()).fit()\n",
    "\n",
    "print(model.summary())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "FZ2ZU89x8SQy",
    "outputId": "605802b5-ef2c-4a89-8059-de3e6a757dca"
   },
   "source": [
    "dw_plot(model)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "uQ1PkGnY08G_",
    "jhiWsG875ev-",
    "yNsYLT_a5b9S",
    "A-q6HWoUbRNw",
    "ZD4NEY-HbL8Y",
    "CgR0_eVTuC-x",
    "VCsIOJnSDJrt",
    "h_EVHRZ_3Z2s"
   ],
   "gpuType": "T4",
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
